{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7f1df4",
   "metadata": {},
   "source": [
    "# Grade: 100 points\n",
    "\n",
    "# Assignment 01: Traditional Machine Learning \n",
    "\n",
    "## Instructions\n",
    "\n",
    "#### Follow These Steps before submitting your assignment \n",
    "\n",
    "This notebook contains the questions for Assignment 1. \n",
    "\n",
    "You must upload this completed Jupyter Notebook file as your submission (other file types are not permitted and will result in a grade of 0).***\n",
    "\n",
    "* If you have trouble running neural network models on your laptop, you can use online platforms, like **[Google Colab](https://colab.research.google.com/)**.\n",
    "* All Figures should have a x- and y-axis label and an appropriate title.\n",
    "**Ensure that your code runs correctly by choosing \"Kernel -> Restart and Cell -> Run All\" before submitting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd59110",
   "metadata": {},
   "source": [
    "# Datasets:\n",
    "\n",
    "`Dataset1.csv` lists the housing market data, where the goal is to predict house prices based on various factors:\n",
    "\n",
    "- SqFt: Square footage of the house\n",
    "- Bedrooms: Number of bedrooms\n",
    "- Bathrooms: Number of bathrooms\n",
    "- Dist_Center: Distance to city center (in miles)\n",
    "- House_Age: Age of the house (years)\n",
    "- Floors: Number of floors\n",
    "- Lot_Size: Lot size (square feet)\n",
    "- Walk_Score: Walkability score (0-100)\n",
    "- HOA_Fee: Monthly HOA fee (if applicable)\n",
    "- Crime_Rate: Local crime rate (incidents per 1000 residents)\n",
    "- Dist_School: Distance to the nearest school (miles)\n",
    "- Grocery_Stores: Number of nearby grocery stores\n",
    "- Prop_Tax: Property tax rate (%)\n",
    "- Maint_Cost: Numerical\tYearly maintenance costs \n",
    "- Median_Income: Household income of the neighborhood (median)\n",
    "- Region: Region (values: 'A', 'B', 'C', 'D', 'E')\n",
    "- House_Cond: House condition ('Low', 'Medium', 'High')\n",
    "- Urban_Rural: Urban/Rural location ('Urban', 'Rural')\n",
    "- House_Price: House price (Target variable)\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "`Dataset2.csv` is a loan status dataset to predict whether a loan application will be fully approved, conditionally approved, or rejected based on various factors:\n",
    "\n",
    "- Credit_Score: Applicant's credit score (300-850, higher is better)\n",
    "- Income: Monthly income\n",
    "- Loan_Amount: Requested loan amount \n",
    "- Loan_Term: Duration of loan (in months)\n",
    "- Debt_Income: Debt-to-income ratio (%)\n",
    "- Open_Accounts: Number of active credit accounts\n",
    "- Hist_Length: Credit history length (years)\n",
    "- Delinquencies: Number of past missed payments\n",
    "- Total_Loan_Balance: Total outstanding loan balance\n",
    "- Credit_Inquiries: Number of recent hard credit inquiries\n",
    "- Employer_Tenure: How long the applicant has been at their job (years)\n",
    "- LTV_Ratio: Loan-to-value ratio (%)\n",
    "- Loan_Purpose: Purpose of the loan (X, Y, Z)\n",
    "- Employment_Type: Employer size (Small, Medium, Large)\n",
    "- Loan_Status: Target Variable(0 is Loan Rejected, 1 is Conditionally Approved, 2 is Fully Approved)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Perceptron, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import label_binarize"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ccc9b9022749034",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d192c12c",
   "metadata": {},
   "source": [
    "# Q1 - Data Loading and Exploration (5 pts)\n",
    "\n",
    "1. Load the Dataset1.\n",
    "2. Display basic statistics and inspect for missing data.\n",
    "3. Encode the categorical features (one-hot encoding). \n",
    "4. Visualize the distribution of all features using histogram.\n",
    "5. **Discussion Question:** Why is it important to explore and visualize the data before building any models? What types of trends or problems could you uncover at this stage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c278db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Dataset1\n",
    "data = pd.read_csv('Dataset1.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Display basic statistics\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e4978d2d711b475",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5bc4d623325d570",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. inspect for missing data\n",
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eae90330fc55c3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 3. Encode the categorical features (one-hot encoding)\n",
    "categorical_cols = ['Region', 'House_Cond', 'Urban_Rural']\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "encoded_array = encoder.fit_transform(df[categorical_cols])\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Drop original categorical columns and merge\n",
    "df_encoded = df.drop(columns=categorical_cols).reset_index(drop=True)\n",
    "df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "df_encoded.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82895bf654d838b1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 4. Visualize the distribution of all features using histogram.\n",
    "\n",
    "# Categorical Features\n",
    "# for column in categorical_cols:\n",
    "#     plt.hist(df[column])\n",
    "#     plt.title(f\"Distribution of {column}\")\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel(\"Count\")\n",
    "#     plt.show()\n",
    "    \n",
    "def plot_histograms(df, columns):\n",
    "    for column in columns:\n",
    "        plt.hist(df[column])\n",
    "        plt.title(f\"Distribution of {column}\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "\n",
    "plot_histograms(df, categorical_cols)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36ebcf467889abf8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "numerical_cols = [column for column in df.columns if column not in categorical_cols]\n",
    "\n",
    "# for column in numerical_cols:\n",
    "#     plt.hist(df_encoded[column])\n",
    "#     plt.title(f\"Distribution of {column}\")\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel(\"Count\")\n",
    "#     plt.show()\n",
    "\n",
    "plot_histograms(df, numerical_cols)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1e3e9ab2f0b69f4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "32f440c6",
   "metadata": {},
   "source": [
    "**Answer to Discussion Question**: \n",
    "1. Detect missing values, outliers in the dataset, so we can conduct proper data cleaning.\n",
    "2. Show feature distributions and feature types in the dataset, so we can conduct proper feature engineering.\n",
    "3. Also, we can predict what models will work for the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478dd942",
   "metadata": {},
   "source": [
    "# Q2 - Outlier Detection (10 pts)\n",
    "1. Train a Gaussian Mixture Model (GMM) on Dataset1 to identify potential outliers.\n",
    "\n",
    "2. Remove the detected outliers and save the cleaned dataset.\n",
    "\n",
    "3. How many outliers you detected?\n",
    "\n",
    "4. Visualize the histogram plot of the remaining data.\n",
    "\n",
    "5. **Discussion Question**: What are outliers? and why it is important to detect them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ee547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train a Gaussian Mixture Model (GMM) on Dataset1 to identify potential outliers.\n",
    "n_components_range = range(1, 31)\n",
    "bic_scores = []\n",
    "aic_scores = []\n",
    "\n",
    "# Exclude the target column (House_Price) from the feature set\n",
    "X = df_encoded.drop(columns=[\"House_Price\"])\n",
    "\n",
    "for n in n_components_range:\n",
    "    gmm = GaussianMixture(n_components=n, random_state=42)\n",
    "    gmm.fit(X)\n",
    "    bic_scores.append(gmm.bic(X))\n",
    "    aic_scores.append(gmm.aic(X))\n",
    "    \n",
    "# Find the number of components that give the minimum BIC and AIC\n",
    "best_n_bic = n_components_range[np.argmin(bic_scores)]\n",
    "best_n_aic = n_components_range[np.argmin(aic_scores)]\n",
    "best_bic_score = min(bic_scores)\n",
    "best_aic_score = min(aic_scores)\n",
    "\n",
    "print(f\"Best n_components according to BIC: {best_n_bic}, BIC Score: {best_bic_score}\")\n",
    "print(f\"Best n_components according to AIC: {best_n_aic}, AIC Score: {best_aic_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the BIC and AIC scores\n",
    "plt.plot(n_components_range, bic_scores, label='BIC', marker='o')\n",
    "plt.plot(n_components_range, aic_scores, label='AIC', marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Score')\n",
    "plt.title('GMM Model Selection Criteria')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d819044e3e8dd1f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=16, random_state=42)\n",
    "gmm.fit(X)\n",
    "\n",
    "# Identify potential outliers\n",
    "# Calculate the log likelihood of each sample under the GMM\n",
    "log_likelihood = gmm.score_samples(X)\n",
    "threshold = np.percentile(log_likelihood, 1)\n",
    "outlier_mask = log_likelihood < threshold\n",
    "\n",
    "outliers = df_encoded[outlier_mask]\n",
    "print(\"Outlier rows:\")\n",
    "print(outliers)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c247b863d7b47af9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. Remove the detected outliers and save the cleaned dataset.\n",
    "df_cleaned = df_encoded.loc[~outlier_mask].reset_index(drop=True)\n",
    "df_cleaned.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5176bfa5c8aa0bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 3. How many outliers you detected?\n",
    "num_outliers = np.sum(outlier_mask)\n",
    "print(\"Number of outliers detected:\", num_outliers)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f808bd6ae884e790",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 4. Visualize the histogram plot of the remaining data.\n",
    "plot_histograms(df_cleaned, df_cleaned.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4c8a8857f3076ef",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "97e12a5d",
   "metadata": {},
   "source": [
    "**Answer to Discussion Question**: \n",
    "1. Outliers are data points that deviate significantly from the rest of a dataset’s distribution.\n",
    "2. Outliers can occur due to measurement errors, data-entry mistakes, or genuine anomalies in the data.\n",
    "3. By detecting and analyzing outliers, we can decide to remove, adjust, or keep outliers, and ensure data integrity and optimize model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f596e02",
   "metadata": {},
   "source": [
    "# Q3 - Correlation and Feature Selection (10 pts)\n",
    "\n",
    "1. Visualize correlations between features and target using a heatmap to identify highly correlated features.\n",
    "2. Select numerical features with correlation above two certain thresholds (0.02 and 0.04), and print them.\n",
    "3. **Discussion Question:** How do you interpret a correlation value? Does a higher correlation always mean a feature is more important?"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1. Visualize correlations between features and target using a heatmap to identify highly correlated features.\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_cleaned.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Features and Target')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f7204e0669ec969",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. Select numerical features with correlation above two certain thresholds (0.02 and 0.04)\n",
    "high_corr_features_0_02 = correlation_matrix['House_Price'][correlation_matrix['House_Price'].abs() > 0.02].index.tolist()\n",
    "high_corr_features_0_04 = correlation_matrix['House_Price'][correlation_matrix['House_Price'].abs() > 0.04].index.tolist()\n",
    "\n",
    "print(\"Numerical features with correlation > 0.02 with House_Price:\", high_corr_features_0_02)\n",
    "print(\"Numerical features with correlation > 0.04 with House_Price:\", high_corr_features_0_04)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42bf4f9f56515c37",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ea694490",
   "metadata": {},
   "source": [
    "**Answer to Discussion Question**: \n",
    "***How do you interpret a correlation value?***\n",
    "1. A correlation value quantifies the degree to which two variables are related.\n",
    "2. This value ranges from -1 to +1:\n",
    "3. +1 represents a perfect positive linear relationship, where increases in one variable correspond to increases in the other.\n",
    "4. -1 represents a perfect negative linear relationship, where increases in one variable correspond to decreases in the other.\n",
    "5. 0 suggests there is no linear relationship between the variables.\n",
    "\n",
    "***Does a higher correlation always mean a feature is more important?***\n",
    "1. No.\n",
    "2. In linear models such as linear regression or logistic regression, multicollinearity can lead to solutions that vary greatly and may be numerically unstable.\n",
    "3. Models like Random forests are effective at identifying interactions between various features, the presence of highly correlated features can obscure these interactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689f657",
   "metadata": {},
   "source": [
    "# Q4 - Multiple Linear Regression (20 pts)\n",
    "\n",
    "1. Build three different subsets of our data using two different sets of features based on correlation thresholds in previous question, as well as the original dataset with all features. For each subset, split the data into train and test and hold out 30% of observations as the test set. Pass random_state=42 to train_test_split to ensure you get the same train and tests sets as the solution and normalize (z-normalization) the data splits. \n",
    "2. Build two different multiple linear regression models using the subsets made by two different thresholds in Q3, and train them on their normalized training sets. \n",
    "3. Now build and fit a Lasso Regression model to the training data using all features in the dataset. The penalization parameter is set to 0.5.\n",
    "4. Evaluate the three models on their test sets and compare the models using R² and RMSE.\n",
    "5. **Discussion Question:** How do we decide which features to include in a multiple linear regression model? What challenges might arise from using too many features?\n",
    "6. **Discussion Question:** Among the three models, which model performs the best and why?\n",
    "7. **Discussion Question:** If a model has a high R² value but a large RMSE, what might that indicate about the model's performance?\n",
    "8. **Discussion Question:** Discuss next steps for potential improvements to the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2591cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build three different subsets of our data using two different sets of features based on correlation thresholds in previous question, as well as the original dataset with all features. For each subset, split the data into train and test and hold out 30% of observations as the test set. Pass random_state=42 to train_test_split to ensure you get the same train and tests sets as the solution and normalize (z-normalization) the data splits. \n",
    "\n",
    "# Subset 1: All features (original dataset)\n",
    "X_all = df_cleaned.drop(columns=[\"House_Price\"])\n",
    "y_all = df_cleaned[\"House_Price\"]\n",
    "\n",
    "# Subset 2: Features with corr > 0.02\n",
    "subset_0_02 = [col for col in high_corr_features_0_02 if col != \"House_Price\"]\n",
    "X_0_02 = df_cleaned[subset_0_02]\n",
    "y_0_02 = df_cleaned[\"House_Price\"]\n",
    "\n",
    "# Subset 3: Features with corr > 0.04\n",
    "subset_0_04 = [col for col in high_corr_features_0_04 if col != \"House_Price\"]\n",
    "X_0_04 = df_cleaned[subset_0_04]\n",
    "y_0_04 = df_cleaned[\"House_Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split each subset into Train and Test and normalize (z-normalization)\n",
    "TEST_SIZE = 0.30\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Subset 1: All features (original dataset)\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(\n",
    "    X_all, y_all, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "scaler_all = StandardScaler()\n",
    "X_train_all_scaled = scaler_all.fit_transform(X_train_all)\n",
    "X_test_all_scaled = scaler_all.transform(X_test_all)\n",
    "\n",
    "# Subset 2: Features with corr > 0.02\n",
    "X_train_02, X_test_02, y_train_02, y_test_02 = train_test_split(\n",
    "    X_0_02, y_0_02, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "scaler_02 = StandardScaler()\n",
    "X_train_02_scaled = scaler_02.fit_transform(X_train_02)\n",
    "X_test_02_scaled = scaler_02.transform(X_test_02)\n",
    "\n",
    "# Subset 3: Features with corr > 0.04\n",
    "X_train_04, X_test_04, y_train_04, y_test_04 = train_test_split(\n",
    "    X_0_04, y_0_04, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "scaler_04 = StandardScaler()\n",
    "X_train_04_scaled = scaler_04.fit_transform(X_train_04)\n",
    "X_test_04_scaled = scaler_04.transform(X_test_04)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e896fe4bb1065c75",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. Build two different multiple linear regression models using the subsets made by two different thresholds in Q3, and train them on their normalized training sets. \n",
    "\n",
    "# Linear Regression for Subset 2\n",
    "lr_model_02 = LinearRegression()\n",
    "lr_model_02.fit(X_train_02_scaled, y_train_02)\n",
    "\n",
    "# Linear Regression for Subset 3\n",
    "lr_model_04 = LinearRegression()\n",
    "lr_model_04.fit(X_train_04_scaled, y_train_04)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20fe59be9737c4d5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 3. Now build and fit a Lasso Regression model to the training data using all features in the dataset. The penalization parameter is set to 0.5.\n",
    "\n",
    "lasso_model_all = Lasso(alpha=0.5, random_state=RANDOM_STATE)\n",
    "lasso_model_all.fit(X_train_all_scaled, y_train_all)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68676f469f2d7438",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 4. Evaluate the three models on their test sets and compare the models using R² and RMSE.\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    predictions = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    print(f\"{model_name} Evaluation\")\n",
    "    print(f\"R^2:  {r2:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Evaluate Linear Regression (corr > 0.02)\n",
    "evaluate_model(lr_model_02, X_test_02_scaled, y_test_02, \n",
    "               model_name=\"Linear Regression (corr > 0.02)\")\n",
    "\n",
    "# Evaluate Linear Regression (corr > 0.04)\n",
    "evaluate_model(lr_model_04, X_test_04_scaled, y_test_04, \n",
    "               model_name=\"Linear Regression (corr > 0.04)\")\n",
    "\n",
    "# Evaluate Lasso Regression (all features)\n",
    "evaluate_model(lasso_model_all, X_test_all_scaled, y_test_all, \n",
    "               model_name=\"Lasso Regression (all features, alpha=0.5)\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5672ec8e18cea3b0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "01ad85d4",
   "metadata": {},
   "source": [
    "**Answer to the first Discussion Question**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964b50a",
   "metadata": {},
   "source": [
    "**Answer to the socond Discussion Question**: \n",
    "***6. Among the three models, which model performs the best and why?***\n",
    "Lasso Regression performs best as it has the highest R² (0.9577) and lowest RMSE (54,355.6510)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d705dc1b",
   "metadata": {},
   "source": [
    "**Answer to the third Discussion Question**: \n",
    "***7. If a model has a high R² value but a large RMSE, what might that indicate about the model's performance?***\n",
    "1. A high R² means the model can explain most of the variance in the target.\n",
    "2. A large RMSE means the model captures overall trends, but individual predictions varies from the actual value suggests there may have some outliers or the scale of target variable is large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead441f9",
   "metadata": {},
   "source": [
    "**Answer to the fourth Discussion Question**: \n",
    "***8. Discuss next steps for potential improvements to the best performing model.***\n",
    "1. We can conduct some feature engineering.\n",
    "2. Use K-fold cross-validation.\n",
    "3. Hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b0b32",
   "metadata": {},
   "source": [
    "# Q 5 - Data Loading and Classification (25 pts)\n",
    "\n",
    "1. Load the Dataset2.\n",
    "2. Display basic statistics and inspect for missing data.\n",
    "3. Encode the categorical features (one-hot encoding). \n",
    "4. Split the data into train, validation and test and hold out 20% and 10% of observations as the validation and test set, respectively. Pass random_state=42.\n",
    "5. Normalize the data (Z-normalization) and fit the following models to the training samples:\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbors (KNN) with K equals to 3\n",
    "- Random Forest (RF) that consists of 5 base decision trees with the maximum depth of 5\n",
    "- Single-Layer Neural Network (Perceptron) with stochastic gradient descent (SGD) optimizer and a learning rate of 0.1, run the model for 10 iterations/epochs.\n",
    "\n",
    "6. Report the training time in milli second for all models. \n",
    "\n",
    "7. Use the Random Forest model you built to generate feature importance scores and a horizontal bar chart to plot the importance scores of all features in descending order. \n",
    "\n",
    "8. Select the important features from most to least important until the accumulated relative importance score reaches 90% or 0.9 and print out the selected features with their importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Dataset2.\n",
    "data = pd.read_csv('Dataset2.csv')\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. Display basic statistics and inspect for missing data.\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb2af68df404590",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a092f9d2c5e922c4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fedfe5a57f6cf61",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2b2d10fc0bfc1c1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 3. Encode the categorical features (one-hot encoding). \n",
    "categorical_cols = ['Loan_Purpose', 'Employment_Type']\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "encoded_array = encoder.fit_transform(df[categorical_cols])\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Drop original categorical columns and merge\n",
    "df_encoded = df.drop(columns=categorical_cols).reset_index(drop=True)\n",
    "df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "df_encoded.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3905344008a43f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 4. Split the data into train, validation and test and hold out 20% and 10% of observations as the validation and test set, respectively. Pass random_state=42.\n",
    "target_col = \"Loan_Status\"\n",
    "\n",
    "X = df_encoded.drop(columns=[target_col])\n",
    "y = df_encoded[target_col]\n",
    "\n",
    "# 10% for the test set\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=42\n",
    ")\n",
    "\n",
    "# 20% for the validation set\n",
    "# 70% for the test set\n",
    "# 0.20 / 0.90 ≈ 0.2222\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2222, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f699b47a483b1057",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Z-normalize (StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "model_training_times = {}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "413e22fc12e85259",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "start_time = time.time()\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "model_training_times['Logistic Regression'] = (end_time - start_time) * 1000"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dcf315befb35417",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# KNN (k=3)\n",
    "start_time = time.time()\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "model_training_times['KNN (k=3)'] = (end_time - start_time) * 1000"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40a375a3863d2e76",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Random Forest (5 trees, max_depth=5)\n",
    "start_time = time.time()\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=5, max_depth=5, random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "model_training_times['Random Forest'] = (end_time - start_time) * 1000"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd7cf3efedb95904",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Single-Layer Neural Network (Perceptron) with SGD (learning_rate=0.1, 10 epochs)\n",
    "start_time = time.time()\n",
    "nn_model = Perceptron(\n",
    "    eta0=0.1,\n",
    "    max_iter=10, \n",
    "    tol=None,\n",
    "    random_state=42\n",
    ")\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "model_training_times['Single-Layer NN (Perceptron)'] = (end_time - start_time) * 1000"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aba6e49574930f1f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"\\n--- Validation Accuracy ---\")\n",
    "print(\"Logistic Regression :\", accuracy_score(y_val, lr_model.predict(X_val_scaled)))\n",
    "print(\"KNN (k=3)           :\", accuracy_score(y_val, knn_model.predict(X_val_scaled)))\n",
    "print(\"Random Forest       :\", accuracy_score(y_val, rf_model.predict(X_val_scaled)))\n",
    "print(\"Perceptron          :\", accuracy_score(y_val, nn_model.predict(X_val_scaled)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c068d9e9988bd7f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 6. Report the training time (in milliseconds) for all models\n",
    "print(\"\\n--- Model Training Times (ms) ---\")\n",
    "for model_name, train_time in model_training_times.items():\n",
    "    print(f\"{model_name}: {train_time:.2f} ms\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c156af6d426baba",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9690be5311436c7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 7. Use the Random Forest model you built to generate feature importance scores and a horizontal bar chart to plot the importance scores of all features in descending order. \n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Sort importances descending\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(range(len(importances)), importances[sorted_idx], align='center')\n",
    "plt.yticks(range(len(importances)), [feature_names[i] for i in sorted_idx])\n",
    "plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.title(\"Random Forest Feature Importances\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b1711893b22c3e0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 8. Select the important features from most to least important until the accumulated relative importance score reaches 90% or 0.9 and print out the selected features with their importance scores\n",
    "accumulated_importance = 0.0\n",
    "total_importance = np.sum(importances)\n",
    "selected_features = []\n",
    "\n",
    "for idx in sorted_idx:\n",
    "    selected_features.append((feature_names[idx], importances[idx]))\n",
    "    accumulated_importance += importances[idx]\n",
    "    if accumulated_importance / total_importance >= 0.90:\n",
    "        break\n",
    "\n",
    "print(\"\\nSelected features until 90% importance reached:\")\n",
    "for feat_name, feat_imp in selected_features:\n",
    "    print(f\"{feat_name}: {feat_imp:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecd932de0a9419c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "463a365b",
   "metadata": {},
   "source": [
    "# Q 6 - Model Selection (10 pts)\n",
    "\n",
    "1. Report the prediction results of all models in Q5 on the test set of Dataset2, using these evaluation metrics: Confusion matrix, F1-score, Recall, Precision and Accuracy. \n",
    "2. Plot the ROC curve and report AUC of the predictions on the test set.\n",
    "3. Report the test time (in millisecond) for all models. \n",
    "4. **Discussion Question:** Why is AUC-ROC a better metric than accuracy for this datasets? Provide an example where accuracy can be misleading.\n",
    "5. **Discussion Question:** Among all models, which one you would choose? why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1606658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Report prediction results on test set: Confusion matrix, F1-score, Recall, Precision, Accuracy\n",
    "\n",
    "def evaluate_classification_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "    else:\n",
    "        # For models lacking 'predict_proba', use decision_function or approximate\n",
    "        # For a strict example, let's just set it to None\n",
    "        y_pred_prob = None\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print or store the results\n",
    "    print(f\"--- {model_name} Evaluation on Test Set ---\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(f\"F1-score:   {f1:.4f}\")\n",
    "    print(f\"Recall:     {recall:.4f}\")\n",
    "    print(f\"Precision:  {precision:.4f}\")\n",
    "    print(f\"Accuracy:   {accuracy:.4f}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_pred_prob\": y_pred_prob,\n",
    "        \"f1_score\": f1,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"accuracy\": accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate all models on the test set\n",
    "results = {}\n",
    "results[\"LogisticRegression\"] = evaluate_classification_model(lr_model, X_test_scaled, y_test, \"Logistic Regression\")\n",
    "results[\"KNN\"]                = evaluate_classification_model(knn_model, X_test_scaled, y_test, \"KNN (k=3)\")\n",
    "results[\"RandomForest\"]       = evaluate_classification_model(rf_model, X_test_scaled, y_test, \"Random Forest\")\n",
    "results[\"Perceptron\"]         = evaluate_classification_model(nn_model, X_test_scaled, y_test, \"Single-Layer NN (Perceptron)\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c8c70b4de3b0fea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. Plot the ROC curve and report AUC for each model on the test set\n",
    "models = {\n",
    "    \"LogisticRegression\": lr_model,\n",
    "    \"KNN (k=3)\": knn_model,\n",
    "    \"RandomForest\": rf_model,\n",
    "    \"Perceptron\": nn_model\n",
    "}\n",
    "\n",
    "classes = [0, 1, 2]\n",
    "y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for model_name, model_obj in models.items():\n",
    "    if hasattr(model_obj, \"predict_proba\"):\n",
    "        y_score = model_obj.predict_proba(X_test_scaled)\n",
    "        \n",
    "        macro_roc_auc = roc_auc_score(\n",
    "            y_test_binarized, y_score, multi_class=\"ovr\", average=\"macro\"\n",
    "        )\n",
    "        micro_roc_auc = roc_auc_score(\n",
    "            y_test_binarized, y_score, multi_class=\"ovr\", average=\"micro\"\n",
    "        )\n",
    "\n",
    "        for i, class_label in enumerate(classes):\n",
    "            fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
    "            auc_val = roc_auc_score(y_test_binarized[:, i], y_score[:, i])\n",
    "            plt.plot(\n",
    "                fpr, tpr, \n",
    "                label=f\"{model_name} - Class {class_label} (AUC={auc_val:.3f})\"\n",
    "            )\n",
    "        \n",
    "    else:\n",
    "        print(f\"{model_name} does not support predict_proba; skipping.\")\n",
    "\n",
    "plt.plot([0,1], [0,1], 'r--', label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Multi-Model ROC Curves (One-vs-Rest)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a73d68527205b92",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 3. Report test time (in milliseconds) for each model\n",
    "test_times = {}\n",
    "\n",
    "for model_name, model in zip(\n",
    "    [\"LogisticRegression\", \"KNN (k=3)\", \"RandomForest\", \"Perceptron\"], \n",
    "    [lr_model, knn_model, rf_model, nn_model]\n",
    "):\n",
    "    start_test_time = time.time()\n",
    "    _ = model.predict(X_test_scaled)\n",
    "    end_test_time = time.time()\n",
    "    test_times[model_name] = (end_test_time - start_test_time) * 1000\n",
    "\n",
    "print(\"\\n--- Model Test Times (ms) ---\")\n",
    "for model_name, t_time in test_times.items():\n",
    "    print(f\"{model_name}: {t_time:.2f} ms\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23e19afc0791ce0b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "98f9e4ee",
   "metadata": {},
   "source": [
    "**Answer to the first Discussion Question:** \n",
    "1. Accuracy can be misleading if one class is significantly more frequent. \n",
    "2. For example, a dataset where 90% of loans are “Fully Approved,” 5% are “Conditionally Approved,” and 5% are “Rejected.” A trivial model predicting “Fully Approved” for every case would achieve 90% accuracy yet fail completely to identify the other classes.\n",
    "3. AUC-ROC captures ranking quality across all possible classification thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b3c4a",
   "metadata": {},
   "source": [
    "**Answer to the second Discussion Question:** \n",
    "1. KNN has the highest overall AUC\n",
    "2. Also, KNN have the highest F1‐score (0.37) and highest recall (0.37), with a slightly lower accuracy.\n",
    "3. In a loan approval scenario, misclassifying an applicant can be costly.\n",
    "4. Although KNN is costly in terms of prediction, and it can be extremely slow with big data, but in this scenario which doesn't need real-time output it will be fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd1824",
   "metadata": {},
   "source": [
    "# Q 7 - Model Selection (20 pts)\n",
    "\n",
    "1. Build a Multi-Layer Perceptron (MLP) and fit it to the normalized training set of Dataset2- The details of the MLP are as follows:\n",
    "   * Two hidden layers (H1, H2), with 50 and 100 neurons/units in H1 and H2, respectively. \n",
    "   * Use tanh function as the activation function for hidden layers.\n",
    "   * Use a proper acitivation function for the output layer.  \n",
    "   * Use Stochastic gradient descent optimizer with a learning rate of 0.1.\n",
    "   * Run the model for 10 iterations/epochs \n",
    "   \n",
    "2.  Report the training time in milli second\n",
    "3.  Record the validation and training loss for each iteration, and make the plot of learning curves (iterations/epochs vs loss).\n",
    "4.  Report the prediction results of MLP on the test set of Dataset2, using these evaluation metrics: Confusion matrix, F1-score, Recall, Precision and Accuracy.\n",
    "5.  Report the test time (in milli second) for MLP. \n",
    "6.  **Analytical Question:** Do you see any signes of overfitting? Why? If it overfits, how would you fix this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770abf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0358745a",
   "metadata": {},
   "source": [
    "**Answer to Discussion Question:**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
